{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167b19d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import glob, os, random, torch, timm, shutil, pickle, time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from tempfile import TemporaryDirectory\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = 'PCI_BUS_ID'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "seed = 0\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f947c298",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c01b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49b121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# class imbalance補正\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d56f3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_dir = '/tf/notebooks/EffNet/Corrected_YOLO_data_123_predict_base456_for_EffNet_train_val/JCO123_corrected_converted_to_YOLO_thacher'\n",
    "train_dir = os.path.join(orig_dir, 'train')\n",
    "data_1 = sorted(glob.glob(train_dir + '/*'))\n",
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5f4fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = '20240415_JCO123_EV2T'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4435f90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_group = []\n",
    "annotated_len =[]\n",
    "for i in data_1:\n",
    "    temp1 = glob.glob(i + '/*.png')\n",
    "    annotated_group.append(os.path.basename(i))\n",
    "    annotated_len.append(len(temp1))\n",
    "    \n",
    "temp_dict = dict(zip(annotated_group,annotated_len))\n",
    "temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9f679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(annotated_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a5091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT = 1/np.array(annotated_len)*sum(annotated_len)/len(annotated_len)\n",
    "WEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d167bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_WEIGHT = dict(zip(list(range(len(annotated_group))), WEIGHT))\n",
    "CLASS_WEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e58912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT = torch.tensor(WEIGHT).cuda()\n",
    "WEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6baa469",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(annotated_group)\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 256\n",
    "WORKERS = 32\n",
    "EPOCHS = 50\n",
    "LR = 3e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38548e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base model \tresolution\n",
    "#EfficientNetB0 \t224\n",
    "#EfficientNetB1 \t240\n",
    "#EfficientNetB2 \t260\n",
    "#EfficientNetB3 \t300\n",
    "#EfficientNetB4 \t380\n",
    "#EfficientNetB5 \t456\n",
    "#EfficientNetB6 \t528\n",
    "#EfficientNetB7 \t600\n",
    "\n",
    "#Efficientnet V2 S \t384\n",
    "#Efficientnet V2 M \t480 \n",
    "#Efficientnet V2 L \t480 \n",
    "#Efficientnetv2 B0 \t224 \n",
    "#Efficientnetv2 B1 \t240 \n",
    "#Efficientnetv2 B2 \t260 \n",
    "#Efficientnetv2 B3 \t300 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d095e893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file save temporaly\n",
    "temp_na = 'best_model_.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4553a815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize early stopping parameters\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fafb1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31291f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_dir = Path(orig_dir + '/train')\n",
    "val_dataset_dir = Path(orig_dir + '/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760f8d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(str(train_dataset_dir) + '/*/*.png')\n",
    "random_idx = np.random.randint(1, len(files), size=9)\n",
    "fig, axes = plt.subplots(3, 3, figsize=(8, 6))\n",
    "\n",
    "for idx, ax in zip(random_idx, axes.ravel()):\n",
    "    img = Image.open(files[idx])\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb951c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.RandAugment(num_ops=3, magnitude=7), \n",
    "        transforms.ToTensor()]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor()])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64f73e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = orig_dir\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=WORKERS)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2f31a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee28a006",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b30df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3b1183",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in enumerate(dataloaders['train']):\n",
    "    if i == 1:\n",
    "        break\n",
    "        \n",
    "print(j[0].size())\n",
    "\n",
    "temp = j[0].to('cpu').detach().numpy().copy()\n",
    "print('max: ', temp.max())\n",
    "print('min: ', temp.min())\n",
    "print('mean: ', temp.mean())\n",
    "print('std: ', temp.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4850ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = np.random.randint(1, BATCH_SIZE, size=9)\n",
    "fig, axes = plt.subplots(3, 3, figsize=(8, 6))\n",
    "\n",
    "for idx, ax in zip(random_idx, axes.ravel()):\n",
    "    img = transforms.ToPILImage()(j[0][idx]) \n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6e3b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede24fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = timm.list_models(pretrained=True)\n",
    "pprint(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7103af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyImgModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model_name: str, pretrained: bool, \n",
    "                 hidden_dim: int, out_dim: int):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(model_name,\n",
    "                                         pretrained=pretrained,\n",
    "                                         num_classes=0)\n",
    "        self.in_features =self.backbone.num_features\n",
    "        self.head = nn.Sequential(nn.Dropout(p=0.2),\n",
    "                                  nn.Linear(self.in_features, hidden_dim),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(p=0.2),\n",
    "                                  nn.Linear(hidden_dim, out_dim))\n",
    "    def forward(self, x):\n",
    "        h = self.backbone(x)\n",
    "        y = self.head(h)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edf07b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selected = 'efficientnetv2_rw_t.ra2_in1k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd89906",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyImgModel(model_name=model_selected, pretrained=True, hidden_dim=256, out_dim=NUM_CLASSES)\n",
    "model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399e6dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6630b7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load weight\n",
    "#model.load_state_dict(torch.load('./XXX'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8035a219",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a913b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_check = timm.create_model(model_name=model_selected, pretrained=True, num_classes=NUM_CLASSES)\n",
    "model_check.default_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12687761",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_check.num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68ffc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_check.feature_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa3e21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, i in enumerate(zip(model.named_parameters(), model.parameters())):\n",
    "    print(n,': ', i[1].requires_grad,': ', i[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d999e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ab9ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f39a013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss(weight = WEIGHT).to(torch.float)\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "# scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.3, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc408135",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 436\n",
    "\n",
    "for i, param in enumerate(model.parameters()):\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for n, i in enumerate(zip(model.named_parameters(), model.parameters())):\n",
    "    if (n >= layer) and ('bn' not in i[0][0]): \n",
    "        i[1].requires_grad = True\n",
    "\n",
    "for n, i in enumerate(zip(model.named_parameters(), model.parameters())):\n",
    "    print(n,': ', i[1].requires_grad,': ', i[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a3407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    since = time.time()\n",
    "    \n",
    "    # Initialize GradScaler for mixed precision\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # Initialize early stopping parameters\n",
    "    counter = 0\n",
    "    best_val_loss = float('inf')\n",
    "    early_stop = False\n",
    "    \n",
    "    filename_prefix = save_name + \"_1st_model.f_\"\n",
    "    \n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, \"best_model.pt\")\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()\n",
    "                else:\n",
    "                    model.eval()\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # Use autocast to enable mixed precision\n",
    "                    with autocast():\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        # Scale the loss and perform backpropagation\n",
    "                        scaler.scale(loss).backward()\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                if phase == 'val':\n",
    "                    scheduler.step(epoch_loss)\n",
    "                    \n",
    "                    if epoch_loss < best_val_loss:\n",
    "                        print(f'Validation loss decreased ({best_val_loss:.4f} --> {epoch_loss:.4f}).  Saving model ...')\n",
    "                        best_val_loss = epoch_loss\n",
    "                        torch.save(model.state_dict(), best_model_params_path)\n",
    "                        \n",
    "                        filepath = f'{filename_prefix}{phase}_ep{epoch:02d}_loss{epoch_loss:.4f}_acc{epoch_acc:.4f}.pt'\n",
    "                        torch.save(model.state_dict(), filepath)\n",
    "                        \n",
    "                        counter = 0\n",
    "                    else:\n",
    "                        counter += 1\n",
    "                        print(f'EarlyStopping counter: {counter} out of {patience}')\n",
    "                        if counter >= patience:\n",
    "                            early_stop = True\n",
    "\n",
    "                if phase == 'val' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "                    \n",
    "                    filepath = f'{filename_prefix}{phase}_ep{epoch:02d}_loss{epoch_loss:.4f}_acc{epoch_acc:.4f}.pt'\n",
    "                    torch.save(model.state_dict(), filepath)\n",
    "                    \n",
    "                    print('lr: ', optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "                    \n",
    "            if early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0697b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model=model, criterion=criterion, optimizer=optimizer, scheduler=scheduler, num_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbb4cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea978dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7ef15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 251\n",
    "\n",
    "for i, param in enumerate(model.parameters()):\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for n, i in enumerate(zip(model.named_parameters(), model.parameters())):\n",
    "    if (n >= layer) and ('bn' not in i[0][0]): \n",
    "        i[1].requires_grad = True\n",
    "\n",
    "for n, i in enumerate(zip(model.named_parameters(), model.parameters())):\n",
    "    print(n,': ', i[1].requires_grad,': ', i[0][0])\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss(weight = WEIGHT).to(torch.float)\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "# scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.3, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7db2f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    since = time.time()\n",
    "    \n",
    "    # Initialize GradScaler for mixed precision\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # Initialize early stopping parameters\n",
    "    counter = 0\n",
    "    best_val_loss = float('inf')\n",
    "    early_stop = False\n",
    "    \n",
    "    filename_prefix = save_name + \"_2nd_model.f_\"\n",
    "    \n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, \"best_model.pt\")\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()\n",
    "                else:\n",
    "                    model.eval()\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # Use autocast to enable mixed precision\n",
    "                    with autocast():\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        # Scale the loss and perform backpropagation\n",
    "                        scaler.scale(loss).backward()\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                if phase == 'val':\n",
    "                    scheduler.step(epoch_loss)\n",
    "                    \n",
    "                    if epoch_loss < best_val_loss:\n",
    "                        print(f'Validation loss decreased ({best_val_loss:.4f} --> {epoch_loss:.4f}).  Saving model ...')\n",
    "                        best_val_loss = epoch_loss\n",
    "                        torch.save(model.state_dict(), best_model_params_path)\n",
    "                        \n",
    "                        filepath = f'{filename_prefix}{phase}_ep{epoch:02d}_loss{epoch_loss:.4f}_acc{epoch_acc:.4f}.pt'\n",
    "                        torch.save(model.state_dict(), filepath)\n",
    "                        \n",
    "                        counter = 0\n",
    "                    else:\n",
    "                        counter += 1\n",
    "                        print(f'EarlyStopping counter: {counter} out of {patience}')\n",
    "                        if counter >= patience:\n",
    "                            early_stop = True\n",
    "\n",
    "                if phase == 'val' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "                    \n",
    "                    filepath = f'{filename_prefix}{phase}_ep{epoch:02d}_loss{epoch_loss:.4f}_acc{epoch_acc:.4f}.pt'\n",
    "                    torch.save(model.state_dict(), filepath)\n",
    "                    \n",
    "                    print('lr: ', optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "                    \n",
    "            if early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15f7def",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model=model, criterion=criterion, optimizer=optimizer, scheduler=scheduler, num_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a17825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b79219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9020aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 134\n",
    "\n",
    "for i, param in enumerate(model.parameters()):\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for n, i in enumerate(zip(model.named_parameters(), model.parameters())):\n",
    "    if (n >= layer) and ('bn' not in i[0][0]): \n",
    "        i[1].requires_grad = True\n",
    "\n",
    "for n, i in enumerate(zip(model.named_parameters(), model.parameters())):\n",
    "    print(n,': ', i[1].requires_grad,': ', i[0][0])\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss(weight = WEIGHT).to(torch.float)\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "# scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.3, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c919f0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    since = time.time()\n",
    "    \n",
    "    # Initialize GradScaler for mixed precision\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # Initialize early stopping parameters\n",
    "    counter = 0\n",
    "    best_val_loss = float('inf')\n",
    "    early_stop = False\n",
    "    \n",
    "    filename_prefix = save_name + \"_3rd_model.f_\"\n",
    "    \n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, \"best_model.pt\")\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()\n",
    "                else:\n",
    "                    model.eval()\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # Use autocast to enable mixed precision\n",
    "                    with autocast():\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        # Scale the loss and perform backpropagation\n",
    "                        scaler.scale(loss).backward()\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                if phase == 'val':\n",
    "                    scheduler.step(epoch_loss)\n",
    "                    \n",
    "                    if epoch_loss < best_val_loss:\n",
    "                        print(f'Validation loss decreased ({best_val_loss:.4f} --> {epoch_loss:.4f}).  Saving model ...')\n",
    "                        best_val_loss = epoch_loss\n",
    "                        torch.save(model.state_dict(), best_model_params_path)\n",
    "                        \n",
    "                        filepath = f'{filename_prefix}{phase}_ep{epoch:02d}_loss{epoch_loss:.4f}_acc{epoch_acc:.4f}.pt'\n",
    "                        torch.save(model.state_dict(), filepath)\n",
    "                        \n",
    "                        counter = 0\n",
    "                    else:\n",
    "                        counter += 1\n",
    "                        print(f'EarlyStopping counter: {counter} out of {patience}')\n",
    "                        if counter >= patience:\n",
    "                            early_stop = True\n",
    "\n",
    "                if phase == 'val' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "                    \n",
    "                    filepath = f'{filename_prefix}{phase}_ep{epoch:02d}_loss{epoch_loss:.4f}_acc{epoch_acc:.4f}.pt'\n",
    "                    torch.save(model.state_dict(), filepath)\n",
    "                    \n",
    "                    print('lr: ', optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "                    \n",
    "            if early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cb13ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model=model, criterion=criterion, optimizer=optimizer, scheduler=scheduler, num_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aaafbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390feb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 56\n",
    "\n",
    "for i, param in enumerate(model.parameters()):\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for n, i in enumerate(zip(model.named_parameters(), model.parameters())):\n",
    "    if (n >= layer) and ('bn' not in i[0][0]): \n",
    "        i[1].requires_grad = True\n",
    "\n",
    "for n, i in enumerate(zip(model.named_parameters(), model.parameters())):\n",
    "    print(n,': ', i[1].requires_grad,': ', i[0][0])\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss(weight = WEIGHT).to(torch.float)\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "# scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.3, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435ffc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    since = time.time()\n",
    "    \n",
    "    # Initialize GradScaler for mixed precision\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # Initialize early stopping parameters\n",
    "    counter = 0\n",
    "    best_val_loss = float('inf')\n",
    "    early_stop = False\n",
    "    \n",
    "    filename_prefix = save_name + \"_4th_model.f_\"\n",
    "    \n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, \"best_model.pt\")\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()\n",
    "                else:\n",
    "                    model.eval()\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # Use autocast to enable mixed precision\n",
    "                    with autocast():\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        # Scale the loss and perform backpropagation\n",
    "                        scaler.scale(loss).backward()\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                if phase == 'val':\n",
    "                    scheduler.step(epoch_loss)\n",
    "                    \n",
    "                    if epoch_loss < best_val_loss:\n",
    "                        print(f'Validation loss decreased ({best_val_loss:.4f} --> {epoch_loss:.4f}).  Saving model ...')\n",
    "                        best_val_loss = epoch_loss\n",
    "                        torch.save(model.state_dict(), best_model_params_path)\n",
    "                        \n",
    "                        filepath = f'{filename_prefix}{phase}_ep{epoch:02d}_loss{epoch_loss:.4f}_acc{epoch_acc:.4f}.pt'\n",
    "                        torch.save(model.state_dict(), filepath)\n",
    "                        \n",
    "                        counter = 0\n",
    "                    else:\n",
    "                        counter += 1\n",
    "                        print(f'EarlyStopping counter: {counter} out of {patience}')\n",
    "                        if counter >= patience:\n",
    "                            early_stop = True\n",
    "\n",
    "                if phase == 'val' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "                    \n",
    "                    filepath = f'{filename_prefix}{phase}_ep{epoch:02d}_loss{epoch_loss:.4f}_acc{epoch_acc:.4f}.pt'\n",
    "                    torch.save(model.state_dict(), filepath)\n",
    "                    \n",
    "                    print('lr: ', optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "                    \n",
    "            if early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cab72d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model=model, criterion=criterion, optimizer=optimizer, scheduler=scheduler, num_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863b7425",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d46480",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 32\n",
    "\n",
    "for i, param in enumerate(model.parameters()):\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for n, i in enumerate(zip(model.named_parameters(), model.parameters())):\n",
    "    if (n >= layer) and ('bn' not in i[0][0]): \n",
    "        i[1].requires_grad = True\n",
    "\n",
    "for n, i in enumerate(zip(model.named_parameters(), model.parameters())):\n",
    "    print(n,': ', i[1].requires_grad,': ', i[0][0])\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss(weight = WEIGHT).to(torch.float)\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "# scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.3, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f8f067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    since = time.time()\n",
    "    \n",
    "    # Initialize GradScaler for mixed precision\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # Initialize early stopping parameters\n",
    "    counter = 0\n",
    "    best_val_loss = float('inf')\n",
    "    early_stop = False\n",
    "    \n",
    "    filename_prefix = save_name + \"_5th_model.f_\"\n",
    "    \n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, \"best_model.pt\")\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()\n",
    "                else:\n",
    "                    model.eval()\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # Use autocast to enable mixed precision\n",
    "                    with autocast():\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        # Scale the loss and perform backpropagation\n",
    "                        scaler.scale(loss).backward()\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                if phase == 'val':\n",
    "                    scheduler.step(epoch_loss)\n",
    "                    \n",
    "                    if epoch_loss < best_val_loss:\n",
    "                        print(f'Validation loss decreased ({best_val_loss:.4f} --> {epoch_loss:.4f}).  Saving model ...')\n",
    "                        best_val_loss = epoch_loss\n",
    "                        torch.save(model.state_dict(), best_model_params_path)\n",
    "                        \n",
    "                        filepath = f'{filename_prefix}{phase}_ep{epoch:02d}_loss{epoch_loss:.4f}_acc{epoch_acc:.4f}.pt'\n",
    "                        torch.save(model.state_dict(), filepath)\n",
    "                        \n",
    "                        counter = 0\n",
    "                    else:\n",
    "                        counter += 1\n",
    "                        print(f'EarlyStopping counter: {counter} out of {patience}')\n",
    "                        if counter >= patience:\n",
    "                            early_stop = True\n",
    "\n",
    "                if phase == 'val' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "                    \n",
    "                    filepath = f'{filename_prefix}{phase}_ep{epoch:02d}_loss{epoch_loss:.4f}_acc{epoch_acc:.4f}.pt'\n",
    "                    torch.save(model.state_dict(), filepath)\n",
    "                    \n",
    "                    print('lr: ', optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "                    \n",
    "            if early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af28960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model=model, criterion=criterion, optimizer=optimizer, scheduler=scheduler, num_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb887051",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaf48dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 8\n",
    "\n",
    "for i, param in enumerate(model.parameters()):\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for n, i in enumerate(zip(model.named_parameters(), model.parameters())):\n",
    "    if (n >= layer) and ('bn' not in i[0][0]): \n",
    "        i[1].requires_grad = True\n",
    "\n",
    "for n, i in enumerate(zip(model.named_parameters(), model.parameters())):\n",
    "    print(n,': ', i[1].requires_grad,': ', i[0][0])\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss(weight = WEIGHT).to(torch.float)\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "# scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.3, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eae5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    since = time.time()\n",
    "    \n",
    "    # Initialize GradScaler for mixed precision\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # Initialize early stopping parameters\n",
    "    counter = 0\n",
    "    best_val_loss = float('inf')\n",
    "    early_stop = False\n",
    "    \n",
    "    filename_prefix = save_name + \"_6th_model.f_\"\n",
    "    \n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, \"best_model.pt\")\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()\n",
    "                else:\n",
    "                    model.eval()\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # Use autocast to enable mixed precision\n",
    "                    with autocast():\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        # Scale the loss and perform backpropagation\n",
    "                        scaler.scale(loss).backward()\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                if phase == 'val':\n",
    "                    scheduler.step(epoch_loss)\n",
    "                    \n",
    "                    if epoch_loss < best_val_loss:\n",
    "                        print(f'Validation loss decreased ({best_val_loss:.4f} --> {epoch_loss:.4f}).  Saving model ...')\n",
    "                        best_val_loss = epoch_loss\n",
    "                        torch.save(model.state_dict(), best_model_params_path)\n",
    "                        \n",
    "                        filepath = f'{filename_prefix}{phase}_ep{epoch:02d}_loss{epoch_loss:.4f}_acc{epoch_acc:.4f}.pt'\n",
    "                        torch.save(model.state_dict(), filepath)\n",
    "                        \n",
    "                        counter = 0\n",
    "                    else:\n",
    "                        counter += 1\n",
    "                        print(f'EarlyStopping counter: {counter} out of {patience}')\n",
    "                        if counter >= patience:\n",
    "                            early_stop = True\n",
    "\n",
    "                if phase == 'val' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "                    \n",
    "                    filepath = f'{filename_prefix}{phase}_ep{epoch:02d}_loss{epoch_loss:.4f}_acc{epoch_acc:.4f}.pt'\n",
    "                    torch.save(model.state_dict(), filepath)\n",
    "                    \n",
    "                    print('lr: ', optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "                    \n",
    "            if early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb536b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model=model, criterion=criterion, optimizer=optimizer, scheduler=scheduler, num_epochs=EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
